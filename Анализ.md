# Анализ задачи

## Что было сделано
Был разработан скрипт на языке Python, который осуществляет парсинг данных с сайта "Quotes to Scrape" (https://quotes.toscrape.com). Скрипт собирает информацию о цитатах и связанных с ними тегах и сохраняет полученные данные в формате JSON.

## Откуда были получены данные
Данные были получены с веб-сайта [Quotes to Scrape](https://quotes.toscrape.com), который предоставляет цитаты различных авторов. Каждая страница содержит информацию о цитатах, авторах и, связанных с цитатами, тегах.

## Как осуществлялся сбор
Сбор данных осуществлялся с помощью библиотеки Python `requests` для отправки HTTP-запросов и `BeautifulSoup` из библиотеки `bs4` для разбора HTML-кода страницы. 

1. **Отправка запроса**: Для каждой из страниц был сформирован URL, на который отправлялся GET-запрос.
2. **Анализ содержимого**: Полученный HTML-код распарсивался с помощью BeautifulSoup, что позволяло извлекать необходимые элементы - цитату, автора и теги.
3. **Сохранение данных**: Данные сохранялись в формате JSON для дальнейшего использования.

## Почему был выбран тот или иной метод/инструмент
- **requests**: Эта библиотека используется для выполнения HTTP-запросов и проста в использовании. Это чуть ли не самая популярна библиотека для отправки запросов.
- **BeautifulSoup**: Данная библиотека предназначена для парсинга HTML и XML документов. Предоставляет простые методы для поиска и извлечения данных из сложных структур, что делает ее идеальной для задач веб-скрапинга.

**Так же одна из причин использования данных библиотек - немалый опыт в их использовании**